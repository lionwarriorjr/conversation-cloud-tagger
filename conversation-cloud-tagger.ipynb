{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline for Detection of Aggressive/Nonconstructive Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora, models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals import joblib\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.pipeline import Pipeline as imb_Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import string\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This::One can make an analogy in mathematical ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`:Clarification for you  (and Zundark's right,...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaI once h...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This::One can make an analogy in mathematical ...  2002   \n",
       "1   4216.0  `:Clarification for you  (and Zundark's right,...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaI once h...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  \n",
       "0       True  article  random  train  \n",
       "1       True     user  random  train  \n",
       "2      False  article  random   test  \n",
       "3       True  article  random  train  \n",
       "4       True  article  random   test  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_comments = pd.read_csv('toxic-data/toxicity_annotated_comments.tsv', encoding='latin-1', sep='\\t')\n",
    "wiki_comments['comment'] = wiki_comments.comment.str.replace('NEWLINE_TOKEN', '')\n",
    "wiki_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3989</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  toxicity  toxicity_score\n",
       "0  2232.0        723         0             0.0\n",
       "1  2232.0       4000         0             0.0\n",
       "2  2232.0       3989         0             1.0\n",
       "3  2232.0       3341         0             0.0\n",
       "4  2232.0       1574         0             1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_annotated = pd.read_csv('toxic-data/toxicity_annotations.tsv', encoding='latin-1', sep='\\t')\n",
    "wiki_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3989</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  toxicity  toxicity_score\n",
       "0  2232.0        723         0             0.0\n",
       "1  2232.0       4000         0             0.0\n",
       "2  2232.0       3989         0             0.0\n",
       "3  2232.0       3341         0             0.0\n",
       "4  2232.0       1574         0             0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [0 if score >= 0 else -score for score in wiki_annotated['toxicity_score']]\n",
    "wiki_annotated['toxicity_score'] = scores\n",
    "wiki_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This::One can make an analogy in mathematical ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>`:Clarification for you  (and Zundark's right,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>`This is such a fun entry.   DevotchkaI once h...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxicity_score\n",
       "0  This::One can make an analogy in mathematical ...             0.0\n",
       "1  `:Clarification for you  (and Zundark's right,...             0.0\n",
       "2                          Elected or Electoral? JHK             0.0\n",
       "3  `This is such a fun entry.   DevotchkaI once h...             0.0\n",
       "4  Please relate the ozone hole to increases in c...             0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = wiki_comments[['rev_id','comment']].merge(wiki_annotated[['rev_id','toxicity_score']], on='rev_id')\n",
    "wiki = wiki.groupby(['rev_id','comment']).agg(lambda x: x.value_counts().index[0]).reset_index()\n",
    "wiki = wiki[['comment', 'toxicity_score']]\n",
    "wiki.columns = ['text', 'toxicity']\n",
    "wiki.to_csv('toxic-data-wiki.csv', index=False)\n",
    "wiki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and that were mentaly retarded</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A tag has been placed on Greg bud fisher, requ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>`*:What about ``Bubble Boy`` as a nickname? It...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>`==Schedule summary==Are we really going to ha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014 (UTC):: No worries guys, these people al...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxicity\n",
       "0                     and that were mentaly retarded       1.0\n",
       "1  A tag has been placed on Greg bud fisher, requ...       0.0\n",
       "2  `*:What about ``Bubble Boy`` as a nickname? It...       0.0\n",
       "3  `==Schedule summary==Are we really going to ha...       0.0\n",
       "4   2014 (UTC):: No worries guys, these people al...       0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('toxic-data-wiki.csv')\n",
    "X = X.sample(frac=1).reset_index()\n",
    "X = X.drop(X.columns[0], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For efficiency, consider only a subset of the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.iloc[0:10000,:]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply PorterStommer and coerce text to appropriate form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mentali retard</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tag place greg bud fisher request speedili del...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bubbl boy nicknam appear vetter call seem reas...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schedul summaryar realli go useless inform top...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014 utc worri guy peopl look anyway 1947 3 de...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxicity\n",
       "0                                     mentali retard       1.0\n",
       "1  tag place greg bud fisher request speedili del...       0.0\n",
       "2  bubbl boy nicknam appear vetter call seem reas...       0.0\n",
       "3  schedul summaryar realli go useless inform top...       0.0\n",
       "4  2014 utc worri guy peopl look anyway 1947 3 de...       0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "p_stemmer = PorterStemmer()\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "for index, row in X.iterrows():\n",
    "    text = row['text'].lower().translate(table)\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [p_stemmer.stem(token) for token in text if token not in stopwords.words('english')]\n",
    "    texts.append(text)\n",
    "    text = ' '.join(text)\n",
    "    X.loc[index,'text'] = text\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainIndex = int(0.65*X.shape[0])\n",
    "trainSet = X.iloc[0:trainIndex,:]\n",
    "testSet = X.iloc[trainIndex:,:]\n",
    "trainTexts, testTexts = texts[0:(trainIndex+1)], texts[trainIndex:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Topic Modeling with Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.005*\"articl\" + 0.004*\"would\" + 0.004*\"peopl\" + 0.004*\"one\" + 0.003*\"state\"'), (1, '0.018*\"articl\" + 0.015*\"page\" + 0.011*\"edit\" + 0.010*\"wikipedia\" + 0.009*\"use\"'), (2, '0.010*\"fuck\" + 0.010*\"ass\" + 0.007*\"live\" + 0.007*\"suck\" + 0.005*\"u\"')]\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(trainTexts)\n",
    "corpus = [dictionary.doc2bow(text) for text in trainTexts]\n",
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=10)\n",
    "print(ldamodel.print_topics(num_topics=3, num_words=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification of Aggressive/Nonconstructive/Constructive Dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE - Synthetic Minority Over-sampling to Accommodate Inbalanced Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smt = SMOTE(random_state=42)\n",
    "vec = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "clf = MultinomialNB()\n",
    "pipeline = imb_Pipeline([('vect', vec),\n",
    "                         ('tfidf', tfidf),\n",
    "                         ('smt', smt), \n",
    "                         ('clf', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Multinomial NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "              'vect__analyzer': ('word', 'char'),\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (0.0001, 0.001, 0.01, 0.1, 1.0)\n",
    "}\n",
    "pipeline = GridSearchCV(pipeline, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = pipeline.fit(trainSet.text, trainSet.toxicity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial NB Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = pipeline.predict(testSet.text)\n",
    "print(classification_report_imbalanced(predicted, testSet.toxicity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_prob = pipeline.predict_proba(testSet.text)\n",
    "predicted_prob = np.matrix.round(predicted_prob, 3)\n",
    "predicted_prob = pd.DataFrame(predicted_prob)\n",
    "predicted_prob['text'] = list(testSet.text)\n",
    "predicted_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(pipeline, 'pipeline_NB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smt = SMOTE(random_state=42)\n",
    "vec = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "clf = SGDClassifier(random_state=42, tol=None, class_weight={2:50})\n",
    "pipeline = imb_Pipeline([('vect', vec),\n",
    "                         ('tfidf', tfidf),\n",
    "                         ('smt', smt), \n",
    "                         ('clf', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "              'vect__analyzer': ('word', 'char'),\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (0.0001, 0.001, 0.01, 0.1, 1.0),\n",
    "              'clf__penalty': ('l2', 'elasticnet'),\n",
    "              'clf__max_iter': (5, 25, 50, 75, 100, 200),\n",
    "              'clf__loss': ('modified_huber', 'hinge')\n",
    "}\n",
    "svm_clf = GridSearchCV(pipeline, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_clf = svm_clf.fit(trainSet.text, trainSet.toxicity)\n",
    "svm_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = svm_clf.predict(testSet.text)\n",
    "print(classification_report_imbalanced(predicted, testSet.toxicity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(svm_clf, 'pipeline_SVM.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(predicted)\n",
    "predicted[1] = list(testSet.toxicity)\n",
    "predicted[2] = list(testSet.text)\n",
    "predicted.columns = ['prediction', 'ground truth', 'text']\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Pipeline with RNNs and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_DOCUMENT_LENGTH = 500\n",
    "EMBEDDING_SIZE = 50\n",
    "n_words = 0\n",
    "MAX_LABEL = 3\n",
    "WORDS_FEATURE = 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_classification(logits, y, mode):\n",
    "    \n",
    "    predicted = tf.argmax(logits, 1)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions={\n",
    "                'class': predicted,\n",
    "                'prob': tf.nn.softmax(logits)\n",
    "            })\n",
    "    \n",
    "    objective = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        # no need to tune learning rate with Adam optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "        trainScore = optimizer.minimize(objective, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=objective, train_op=trainScore)\n",
    "    \n",
    "    evaluated = {'accuracy': tf.metrics.accuracy(labels=y, predictions=predicted)}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=objective, eval_metric_ops=evaluated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(features, labels, mode):\n",
    "    \n",
    "    word_vectors = tf.contrib.layers.embed_sequence(\n",
    "        features[WORDS_FEATURE], vocab_size=n_words, embed_dim=EMBEDDING_SIZE)\n",
    "    word_list = tf.unstack(word_vectors, axis=1)\n",
    "    \n",
    "    cell = tf.nn.rnn_cell.GRUCell(EMBEDDING_SIZE)\n",
    "    \n",
    "    _, encoding = tf.nn.static_rnn(cell, word_list, dtype=tf.float32)\n",
    "    \n",
    "    logits = tf.layers.dense(encoding, MAX_LABEL, activation=None)\n",
    "    \n",
    "    return softmax_classification(logits=logits, y=labels, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global n_words\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "trainTransform = processor.fit_transform(trainSet.text)\n",
    "testTransform = processor.fit_transform(testSet.text)\n",
    "trainTransform = np.array(list(trainTransform))\n",
    "testTransform = np.array(list(testTransform))\n",
    "\n",
    "n_words = len(processor.vocabulary_)\n",
    "num_steps = 5000 # number of optimization steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainLabels = np.array(trainSet.toxicity)\n",
    "testLabels = np.array(testSet.toxicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = tf.estimator.Estimator(model_fn=RNN)\n",
    "trainFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={WORDS_FEATURE: trainTransform},\n",
    "    y=trainLabels,\n",
    "    batch_size=len(trainTransform),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "rnn.train(input_fn=trainFunc, steps=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={WORDS_FEATURE: testTransform}, y=testLabels, num_epochs=1, shuffle=False)\n",
    "pred = rnn.predict(input_fn=testFunc)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred['text'] = list(testSet.text)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = np.array(pred['class'])\n",
    "print(classification_report_imbalanced(predicted, testSet.toxicity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(rnn, 'pipeline_RNN.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
