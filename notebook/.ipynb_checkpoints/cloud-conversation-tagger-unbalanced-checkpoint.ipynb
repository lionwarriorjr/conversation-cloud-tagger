{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline for Detection of Aggressive/Nonconstructive Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora, models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals import joblib\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.pipeline import Pipeline as imb_Pipeline\n",
    "import string\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This::One can make an analogy in mathematical ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`:Clarification for you  (and Zundark's right,...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaI once h...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This::One can make an analogy in mathematical ...  2002   \n",
       "1   4216.0  `:Clarification for you  (and Zundark's right,...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaI once h...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  \n",
       "0       True  article  random  train  \n",
       "1       True     user  random  train  \n",
       "2      False  article  random   test  \n",
       "3       True  article  random  train  \n",
       "4       True  article  random   test  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_comments = pd.read_csv('toxic-data/toxicity_annotated_comments.tsv', encoding='latin-1', sep='\\t')\n",
    "wiki_comments['comment'] = wiki_comments.comment.str.replace('NEWLINE_TOKEN', '')\n",
    "wiki_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3989</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  toxicity  toxicity_score\n",
       "0  2232.0        723         0             0.0\n",
       "1  2232.0       4000         0             0.0\n",
       "2  2232.0       3989         0             1.0\n",
       "3  2232.0       3341         0             0.0\n",
       "4  2232.0       1574         0             1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_annotated = pd.read_csv('toxic-data/toxicity_annotations.tsv', encoding='latin-1', sep='\\t')\n",
    "wiki_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3989</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  toxicity  toxicity_score\n",
       "0  2232.0        723         0             0.0\n",
       "1  2232.0       4000         0             0.0\n",
       "2  2232.0       3989         0             0.0\n",
       "3  2232.0       3341         0             0.0\n",
       "4  2232.0       1574         0             0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [0 if score >= 0 else -score for score in wiki_annotated['toxicity_score']]\n",
    "wiki_annotated['toxicity_score'] = scores\n",
    "wiki_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This::One can make an analogy in mathematical ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>`:Clarification for you  (and Zundark's right,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>`This is such a fun entry.   DevotchkaI once h...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxicity\n",
       "0  This::One can make an analogy in mathematical ...       0.0\n",
       "1  `:Clarification for you  (and Zundark's right,...       0.0\n",
       "2                          Elected or Electoral? JHK       0.0\n",
       "3  `This is such a fun entry.   DevotchkaI once h...       0.0\n",
       "4  Please relate the ozone hole to increases in c...       0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = wiki_comments[['rev_id','comment']].merge(wiki_annotated[['rev_id','toxicity_score']], on='rev_id')\n",
    "wiki = wiki.groupby(['rev_id','comment']).agg(lambda x: x.value_counts().index[0]).reset_index()\n",
    "wiki = wiki[['comment', 'toxicity_score']]\n",
    "wiki.columns = ['text', 'toxicity']\n",
    "wiki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REDIRECT Talk:U.S. Route 64 Alternate (Rocky M...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>== Couple changes ==I made a couple changes, e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>`Please do not remove messages from your talk ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Darth Binkys name is in red, and  says mec wha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`*The following is what is currently written i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxicity\n",
       "0  REDIRECT Talk:U.S. Route 64 Alternate (Rocky M...       0.0\n",
       "1  == Couple changes ==I made a couple changes, e...       0.0\n",
       "2  `Please do not remove messages from your talk ...       0.0\n",
       "3  Darth Binkys name is in red, and  says mec wha...       0.0\n",
       "4  `*The following is what is currently written i...       0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = wiki\n",
    "X = X.sample(frac=1).reset_index()\n",
    "X = X.drop(X.columns[0], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For efficiency, consider only a subset of the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.iloc[0:10000,:]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply PorterStommer and coerce text to appropriate form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>redirect talku rout 64 altern rocki mounttarbo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coupl chang made coupl chang explain hereremov...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pleas remov messag talk page talk page exist r...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>darth binki name red say mec what clan call</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>follow current written religion section fine i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxicity\n",
       "0  redirect talku rout 64 altern rocki mounttarbo...       0.0\n",
       "1  coupl chang made coupl chang explain hereremov...       0.0\n",
       "2  pleas remov messag talk page talk page exist r...       0.0\n",
       "3        darth binki name red say mec what clan call       0.0\n",
       "4  follow current written religion section fine i...       0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "p_stemmer = PorterStemmer()\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "for index, row in X.iterrows():\n",
    "    text = row['text'].lower().translate(table)\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [p_stemmer.stem(token) for token in text if token not in stopwords.words('english')]\n",
    "    texts.append(text)\n",
    "    text = ' '.join(text)\n",
    "    X.loc[index,'text'] = text\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainIndex = int(0.65*X.shape[0])\n",
    "trainSet = X.iloc[0:trainIndex,:]\n",
    "testSet = X.iloc[trainIndex:,:]\n",
    "trainTexts, testTexts = texts[0:(trainIndex+1)], texts[trainIndex:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Topic Modeling with Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.004*\"one\" + 0.003*\"like\" + 0.003*\"test\" + 0.003*\"also\" + 0.003*\"concernthank\"'), (1, '0.020*\"articl\" + 0.008*\"sourc\" + 0.007*\"would\" + 0.006*\"use\" + 0.006*\"one\"'), (2, '0.019*\"page\" + 0.014*\"edit\" + 0.010*\"wikipedia\" + 0.010*\"block\" + 0.009*\"pleas\"')]\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(trainTexts)\n",
    "corpus = [dictionary.doc2bow(text) for text in trainTexts]\n",
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=10)\n",
    "print(ldamodel.print_topics(num_topics=3, num_words=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification of Aggressive/Nonconstructive/Constructive Dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE - Synthetic Minority Over-sampling to Accommodate Inbalanced Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#smt = SMOTE(random_state=42)\n",
    "vec = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "clf = MultinomialNB()\n",
    "pipeline = imb_Pipeline([('vect', vec),\n",
    "                         ('tfidf', tfidf),\n",
    "                         #('smt', smt), \n",
    "                         ('clf', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Multinomial NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "              'vect__analyzer': ('word', 'char'),\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (0.0001, 0.001, 0.01, 0.1, 1.0)\n",
    "}\n",
    "pipeline = RandomizedSearchCV(pipeline, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pipeline = pipeline.fit(trainSet.text, trainSet.toxicity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial NB Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       1.00      0.92      0.88      0.96      0.53      0.30      3387\n",
      "        1.0       0.21      0.59      0.93      0.31      0.46      0.19       108\n",
      "        2.0       0.04      0.40      0.99      0.07      0.19      0.03         5\n",
      "\n",
      "avg / total       0.97      0.91      0.88      0.94      0.52      0.29      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = pipeline.predict(testSet.text)\n",
    "print(classification_report_imbalanced(predicted, testSet.toxicity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>text</th>\n",
       "      <th>ground truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>specul sourc notabl sens gener known eg appear...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>agre complet polici debat belong somewher els ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>didnt malign anyon person anyon name mention a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>may misrepres said repeatedli past may opinion...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mark amerikaa far tell compar work look mark p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.005</td>\n",
       "      <td>give messag</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>krystal jenkin hi ad dbbio templat articl krys...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>problem may want drop unblock request talk pag...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.965</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.001</td>\n",
       "      <td>wont let dont</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>say leav everyth written psa written togeth al...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>imagerobert wadlowjpg jeffrey pleas stop tag i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>careeri read section 4 time couldnt find mista...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>news note understand concern thought revis wor...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>dev920 sophomor henc naiv argument evid clear ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>well peopl look scottish clan come articl done...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>topic cover feel need go exactli inform neithe...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>august 2007a tag place dinesh robinson request...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.317</td>\n",
       "      <td>fuck fuck fuck youa</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>editth commerci recept section wrong gross cou...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>hi see respons yoour talk page best wish pleas...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.967</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>ad</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>explan dear edjohnston bearian harm one put un...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.001</td>\n",
       "      <td>dont delet work lover kornfan71 either</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>wait see mention articl get end see</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>littl evid anonym user servic admit claim disc...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>ill talk made comment lefthandsid equat dont p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>fresh start alright neil let tri begin hope be...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>delawar counti gener post counti rout number s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>realli happi hunt post iraq small parcel actua...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>dont love happi endingo lineto linewak time ne...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>andor szentivanyi dean medicin lobbi moffitt c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>entir articl full sentencen like oper blow hea...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.008</td>\n",
       "      <td>lmao report ahahahahahahahahahahahahahahahahah...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>doesnt realli sound like perform issu</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>0.976</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.007</td>\n",
       "      <td>good morn labour wikipedia fuckhead</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>juli 2009 utcfyunclick vs outsid sourceswikipe...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>higletti decid move page amber sherlock use ma...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>0.638</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.109</td>\n",
       "      <td>lesbian true lesbian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>someth see youv accus past</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>0.994</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>thank explain send messag</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>thank thank particip rfa pass final count 42 s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>agre epidemiolog manganes concentr scrapieaffe...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>januari 2008pleas stop continu vandal page blo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>remov</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>sticker slowli turn transpar ive seenus sticke...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>februari 2009 hey dude great addit sale aol al...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>locat kalamb wrongli shown correct tkul</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>0.976</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.001</td>\n",
       "      <td>appli also right</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>relationship section look page stumbl upon oo ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>block edit period 24 hour vandal wikipedia wis...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>0.702</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.005</td>\n",
       "      <td>bullshit appropri wikipedia lol</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>here case want debat site professorselfpublish...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>thank thank take time particip rfa hope abl im...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.003</td>\n",
       "      <td>right free speach</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>utter disgrac deliber attempt silenc free ordi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>dont understand edit last paragraph end edit o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>0.994</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>dont think particular reason countri enter fir...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>award nomin award nomin long point need articl...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>0.984</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>stupid chines wannab your vietnames admit pull...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>hate im tri add truth greater metavers god will</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2                                               text  \\\n",
       "0     1.000  0.000  0.000  specul sourc notabl sens gener known eg appear...   \n",
       "1     1.000  0.000  0.000  agre complet polici debat belong somewher els ...   \n",
       "2     1.000  0.000  0.000  didnt malign anyon person anyon name mention a...   \n",
       "3     1.000  0.000  0.000  may misrepres said repeatedli past may opinion...   \n",
       "4     1.000  0.000  0.000  mark amerikaa far tell compar work look mark p...   \n",
       "5     0.899  0.097  0.005                                        give messag   \n",
       "6     1.000  0.000  0.000  krystal jenkin hi ad dbbio templat articl krys...   \n",
       "7     0.999  0.001  0.000  problem may want drop unblock request talk pag...   \n",
       "8     0.965  0.034  0.001                                      wont let dont   \n",
       "9     0.980  0.020  0.000  say leav everyth written psa written togeth al...   \n",
       "10    1.000  0.000  0.000  imagerobert wadlowjpg jeffrey pleas stop tag i...   \n",
       "11    0.999  0.001  0.000  careeri read section 4 time couldnt find mista...   \n",
       "12    1.000  0.000  0.000  news note understand concern thought revis wor...   \n",
       "13    0.999  0.001  0.000  dev920 sophomor henc naiv argument evid clear ...   \n",
       "14    0.997  0.003  0.000  well peopl look scottish clan come articl done...   \n",
       "15    1.000  0.000  0.000  topic cover feel need go exactli inform neithe...   \n",
       "16    1.000  0.000  0.000  august 2007a tag place dinesh robinson request...   \n",
       "17    0.003  0.680  0.317                                fuck fuck fuck youa   \n",
       "18    1.000  0.000  0.000  editth commerci recept section wrong gross cou...   \n",
       "19    0.998  0.002  0.000  hi see respons yoour talk page best wish pleas...   \n",
       "20    0.967  0.033  0.000                                                 ad   \n",
       "21    1.000  0.000  0.000  explan dear edjohnston bearian harm one put un...   \n",
       "22    0.972  0.027  0.001             dont delet work lover kornfan71 either   \n",
       "23    0.978  0.022  0.000                wait see mention articl get end see   \n",
       "24    1.000  0.000  0.000  littl evid anonym user servic admit claim disc...   \n",
       "25    0.987  0.013  0.000  ill talk made comment lefthandsid equat dont p...   \n",
       "26    1.000  0.000  0.000  fresh start alright neil let tri begin hope be...   \n",
       "27    1.000  0.000  0.000  delawar counti gener post counti rout number s...   \n",
       "28    0.998  0.002  0.000  realli happi hunt post iraq small parcel actua...   \n",
       "29    0.985  0.015  0.000  dont love happi endingo lineto linewak time ne...   \n",
       "...     ...    ...    ...                                                ...   \n",
       "3470  0.999  0.001  0.000  andor szentivanyi dean medicin lobbi moffitt c...   \n",
       "3471  1.000  0.000  0.000  entir articl full sentencen like oper blow hea...   \n",
       "3472  0.175  0.817  0.008  lmao report ahahahahahahahahahahahahahahahahah...   \n",
       "3473  0.990  0.010  0.000              doesnt realli sound like perform issu   \n",
       "3474  0.976  0.017  0.007                good morn labour wikipedia fuckhead   \n",
       "3475  1.000  0.000  0.000  juli 2009 utcfyunclick vs outsid sourceswikipe...   \n",
       "3476  0.995  0.005  0.000  higletti decid move page amber sherlock use ma...   \n",
       "3477  0.638  0.252  0.109                               lesbian true lesbian   \n",
       "3478  0.981  0.019  0.000                         someth see youv accus past   \n",
       "3479  0.994  0.006  0.000                          thank explain send messag   \n",
       "3480  1.000  0.000  0.000  thank thank particip rfa pass final count 42 s...   \n",
       "3481  0.991  0.009  0.000  agre epidemiolog manganes concentr scrapieaffe...   \n",
       "3482  0.999  0.001  0.000  januari 2008pleas stop continu vandal page blo...   \n",
       "3483  0.977  0.022  0.000                                              remov   \n",
       "3484  0.999  0.001  0.000  sticker slowli turn transpar ive seenus sticke...   \n",
       "3485  0.999  0.001  0.000  februari 2009 hey dude great addit sale aol al...   \n",
       "3486  0.998  0.001  0.001            locat kalamb wrongli shown correct tkul   \n",
       "3487  0.976  0.024  0.001                                   appli also right   \n",
       "3488  0.999  0.001  0.000  relationship section look page stumbl upon oo ...   \n",
       "3489  1.000  0.000  0.000  block edit period 24 hour vandal wikipedia wis...   \n",
       "3490  0.702  0.292  0.005                    bullshit appropri wikipedia lol   \n",
       "3491  1.000  0.000  0.000  here case want debat site professorselfpublish...   \n",
       "3492  1.000  0.000  0.000  thank thank take time particip rfa hope abl im...   \n",
       "3493  0.907  0.090  0.003                                  right free speach   \n",
       "3494  0.998  0.002  0.000  utter disgrac deliber attempt silenc free ordi...   \n",
       "3495  0.997  0.003  0.000  dont understand edit last paragraph end edit o...   \n",
       "3496  0.994  0.006  0.000  dont think particular reason countri enter fir...   \n",
       "3497  0.997  0.003  0.000  award nomin award nomin long point need articl...   \n",
       "3498  0.984  0.016  0.000  stupid chines wannab your vietnames admit pull...   \n",
       "3499  0.995  0.005  0.000    hate im tri add truth greater metavers god will   \n",
       "\n",
       "      ground truth  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "5              0.0  \n",
       "6              0.0  \n",
       "7              0.0  \n",
       "8              0.0  \n",
       "9              0.0  \n",
       "10             0.0  \n",
       "11             0.0  \n",
       "12             0.0  \n",
       "13             0.0  \n",
       "14             0.0  \n",
       "15             0.0  \n",
       "16             0.0  \n",
       "17             2.0  \n",
       "18             0.0  \n",
       "19             0.0  \n",
       "20             0.0  \n",
       "21             0.0  \n",
       "22             0.0  \n",
       "23             0.0  \n",
       "24             0.0  \n",
       "25             0.0  \n",
       "26             0.0  \n",
       "27             0.0  \n",
       "28             1.0  \n",
       "29             0.0  \n",
       "...            ...  \n",
       "3470           0.0  \n",
       "3471           0.0  \n",
       "3472           1.0  \n",
       "3473           0.0  \n",
       "3474           1.0  \n",
       "3475           0.0  \n",
       "3476           0.0  \n",
       "3477           0.0  \n",
       "3478           0.0  \n",
       "3479           0.0  \n",
       "3480           0.0  \n",
       "3481           0.0  \n",
       "3482           0.0  \n",
       "3483           0.0  \n",
       "3484           0.0  \n",
       "3485           0.0  \n",
       "3486           0.0  \n",
       "3487           0.0  \n",
       "3488           0.0  \n",
       "3489           0.0  \n",
       "3490           1.0  \n",
       "3491           0.0  \n",
       "3492           0.0  \n",
       "3493           0.0  \n",
       "3494           0.0  \n",
       "3495           0.0  \n",
       "3496           0.0  \n",
       "3497           0.0  \n",
       "3498           1.0  \n",
       "3499           0.0  \n",
       "\n",
       "[3500 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_prob = pipeline.predict_proba(testSet.text)\n",
    "predicted_prob = np.matrix.round(predicted_prob, 3)\n",
    "predicted_prob = pd.DataFrame(predicted_prob)\n",
    "predicted_prob['text'] = list(testSet.text)\n",
    "predicted_prob['ground truth'] = list(testSet.toxicity)\n",
    "predicted_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline_NB.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'pipeline_NB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#smt = SMOTE(random_state=42)\n",
    "vec = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "clf = SGDClassifier(random_state=42, tol=None, class_weight={1:50,2:100})\n",
    "pipeline = imb_Pipeline([('vect', vec),\n",
    "                         ('tfidf', tfidf),\n",
    "                         #('smt', smt), \n",
    "                         ('clf', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "              'vect__analyzer': ('word', 'char'),\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (0.0001, 0.001, 0.01, 0.1, 1.0),\n",
    "              'clf__penalty': ('l2', 'elasticnet'),\n",
    "              'clf__max_iter': (5, 25, 50, 75, 100, 200),\n",
    "              'clf__loss': ('modified_huber', 'hinge')\n",
    "}\n",
    "svm_clf = RandomizedSearchCV(pipeline, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9184615384615384"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = svm_clf.fit(trainSet.text, trainSet.toxicity)\n",
    "svm_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       1.00      0.93      0.94      0.96      0.58      0.36      3371\n",
      "        1.0       0.25      0.68      0.93      0.37      0.50      0.23       113\n",
      "        2.0       0.15      0.50      0.99      0.23      0.39      0.14        16\n",
      "\n",
      "avg / total       0.97      0.92      0.94      0.94      0.58      0.36      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = svm_clf.predict(testSet.text)\n",
    "print(classification_report_imbalanced(predicted, testSet.toxicity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground truth</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>specul sourc notabl sens gener known eg appear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>agre complet polici debat belong somewher els ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>didnt malign anyon person anyon name mention a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>may misrepres said repeatedli past may opinion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mark amerikaa far tell compar work look mark p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>give messag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>krystal jenkin hi ad dbbio templat articl krys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>problem may want drop unblock request talk pag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wont let dont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>say leav everyth written psa written togeth al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>imagerobert wadlowjpg jeffrey pleas stop tag i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>careeri read section 4 time couldnt find mista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>news note understand concern thought revis wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dev920 sophomor henc naiv argument evid clear ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>well peopl look scottish clan come articl done...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>topic cover feel need go exactli inform neithe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>august 2007a tag place dinesh robinson request...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>fuck fuck fuck youa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>editth commerci recept section wrong gross cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hi see respons yoour talk page best wish pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>explan dear edjohnston bearian harm one put un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dont delet work lover kornfan71 either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wait see mention articl get end see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>littl evid anonym user servic admit claim disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ill talk made comment lefthandsid equat dont p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fresh start alright neil let tri begin hope be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>delawar counti gener post counti rout number s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>realli happi hunt post iraq small parcel actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dont love happi endingo lineto linewak time ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>andor szentivanyi dean medicin lobbi moffitt c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>entir articl full sentencen like oper blow hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lmao report ahahahahahahahahahahahahahahahahah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>doesnt realli sound like perform issu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good morn labour wikipedia fuckhead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>juli 2009 utcfyunclick vs outsid sourceswikipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>higletti decid move page amber sherlock use ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>lesbian true lesbian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>someth see youv accus past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thank explain send messag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thank thank particip rfa pass final count 42 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>agre epidemiolog manganes concentr scrapieaffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>januari 2008pleas stop continu vandal page blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>remov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sticker slowli turn transpar ive seenus sticke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>februari 2009 hey dude great addit sale aol al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>locat kalamb wrongli shown correct tkul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>appli also right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>relationship section look page stumbl upon oo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>block edit period 24 hour vandal wikipedia wis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bullshit appropri wikipedia lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>here case want debat site professorselfpublish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thank thank take time particip rfa hope abl im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>right free speach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>utter disgrac deliber attempt silenc free ordi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dont understand edit last paragraph end edit o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dont think particular reason countri enter fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>award nomin award nomin long point need articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>stupid chines wannab your vietnames admit pull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hate im tri add truth greater metavers god will</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction  ground truth  \\\n",
       "0            0.0           0.0   \n",
       "1            0.0           0.0   \n",
       "2            0.0           0.0   \n",
       "3            0.0           0.0   \n",
       "4            0.0           0.0   \n",
       "5            0.0           0.0   \n",
       "6            0.0           0.0   \n",
       "7            0.0           0.0   \n",
       "8            0.0           0.0   \n",
       "9            0.0           0.0   \n",
       "10           0.0           0.0   \n",
       "11           0.0           0.0   \n",
       "12           0.0           0.0   \n",
       "13           0.0           0.0   \n",
       "14           0.0           0.0   \n",
       "15           0.0           0.0   \n",
       "16           0.0           0.0   \n",
       "17           2.0           2.0   \n",
       "18           0.0           0.0   \n",
       "19           0.0           0.0   \n",
       "20           0.0           0.0   \n",
       "21           0.0           0.0   \n",
       "22           0.0           0.0   \n",
       "23           0.0           0.0   \n",
       "24           0.0           0.0   \n",
       "25           0.0           0.0   \n",
       "26           0.0           0.0   \n",
       "27           0.0           0.0   \n",
       "28           0.0           1.0   \n",
       "29           0.0           0.0   \n",
       "...          ...           ...   \n",
       "3470         0.0           0.0   \n",
       "3471         0.0           0.0   \n",
       "3472         0.0           1.0   \n",
       "3473         0.0           0.0   \n",
       "3474         0.0           1.0   \n",
       "3475         0.0           0.0   \n",
       "3476         0.0           0.0   \n",
       "3477         0.0           0.0   \n",
       "3478         0.0           0.0   \n",
       "3479         0.0           0.0   \n",
       "3480         0.0           0.0   \n",
       "3481         0.0           0.0   \n",
       "3482         0.0           0.0   \n",
       "3483         0.0           0.0   \n",
       "3484         0.0           0.0   \n",
       "3485         0.0           0.0   \n",
       "3486         0.0           0.0   \n",
       "3487         0.0           0.0   \n",
       "3488         0.0           0.0   \n",
       "3489         0.0           0.0   \n",
       "3490         0.0           1.0   \n",
       "3491         0.0           0.0   \n",
       "3492         0.0           0.0   \n",
       "3493         0.0           0.0   \n",
       "3494         0.0           0.0   \n",
       "3495         0.0           0.0   \n",
       "3496         0.0           0.0   \n",
       "3497         0.0           0.0   \n",
       "3498         1.0           1.0   \n",
       "3499         0.0           0.0   \n",
       "\n",
       "                                                   text  \n",
       "0     specul sourc notabl sens gener known eg appear...  \n",
       "1     agre complet polici debat belong somewher els ...  \n",
       "2     didnt malign anyon person anyon name mention a...  \n",
       "3     may misrepres said repeatedli past may opinion...  \n",
       "4     mark amerikaa far tell compar work look mark p...  \n",
       "5                                           give messag  \n",
       "6     krystal jenkin hi ad dbbio templat articl krys...  \n",
       "7     problem may want drop unblock request talk pag...  \n",
       "8                                         wont let dont  \n",
       "9     say leav everyth written psa written togeth al...  \n",
       "10    imagerobert wadlowjpg jeffrey pleas stop tag i...  \n",
       "11    careeri read section 4 time couldnt find mista...  \n",
       "12    news note understand concern thought revis wor...  \n",
       "13    dev920 sophomor henc naiv argument evid clear ...  \n",
       "14    well peopl look scottish clan come articl done...  \n",
       "15    topic cover feel need go exactli inform neithe...  \n",
       "16    august 2007a tag place dinesh robinson request...  \n",
       "17                                  fuck fuck fuck youa  \n",
       "18    editth commerci recept section wrong gross cou...  \n",
       "19    hi see respons yoour talk page best wish pleas...  \n",
       "20                                                   ad  \n",
       "21    explan dear edjohnston bearian harm one put un...  \n",
       "22               dont delet work lover kornfan71 either  \n",
       "23                  wait see mention articl get end see  \n",
       "24    littl evid anonym user servic admit claim disc...  \n",
       "25    ill talk made comment lefthandsid equat dont p...  \n",
       "26    fresh start alright neil let tri begin hope be...  \n",
       "27    delawar counti gener post counti rout number s...  \n",
       "28    realli happi hunt post iraq small parcel actua...  \n",
       "29    dont love happi endingo lineto linewak time ne...  \n",
       "...                                                 ...  \n",
       "3470  andor szentivanyi dean medicin lobbi moffitt c...  \n",
       "3471  entir articl full sentencen like oper blow hea...  \n",
       "3472  lmao report ahahahahahahahahahahahahahahahahah...  \n",
       "3473              doesnt realli sound like perform issu  \n",
       "3474                good morn labour wikipedia fuckhead  \n",
       "3475  juli 2009 utcfyunclick vs outsid sourceswikipe...  \n",
       "3476  higletti decid move page amber sherlock use ma...  \n",
       "3477                               lesbian true lesbian  \n",
       "3478                         someth see youv accus past  \n",
       "3479                          thank explain send messag  \n",
       "3480  thank thank particip rfa pass final count 42 s...  \n",
       "3481  agre epidemiolog manganes concentr scrapieaffe...  \n",
       "3482  januari 2008pleas stop continu vandal page blo...  \n",
       "3483                                              remov  \n",
       "3484  sticker slowli turn transpar ive seenus sticke...  \n",
       "3485  februari 2009 hey dude great addit sale aol al...  \n",
       "3486            locat kalamb wrongli shown correct tkul  \n",
       "3487                                   appli also right  \n",
       "3488  relationship section look page stumbl upon oo ...  \n",
       "3489  block edit period 24 hour vandal wikipedia wis...  \n",
       "3490                    bullshit appropri wikipedia lol  \n",
       "3491  here case want debat site professorselfpublish...  \n",
       "3492  thank thank take time particip rfa hope abl im...  \n",
       "3493                                  right free speach  \n",
       "3494  utter disgrac deliber attempt silenc free ordi...  \n",
       "3495  dont understand edit last paragraph end edit o...  \n",
       "3496  dont think particular reason countri enter fir...  \n",
       "3497  award nomin award nomin long point need articl...  \n",
       "3498  stupid chines wannab your vietnames admit pull...  \n",
       "3499    hate im tri add truth greater metavers god will  \n",
       "\n",
       "[3500 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = pd.DataFrame(predicted)\n",
    "predicted[1] = list(testSet.toxicity)\n",
    "predicted[2] = list(testSet.text)\n",
    "predicted.columns = ['prediction', 'ground truth', 'text']\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline_SVM.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_clf, 'pipeline_SVM.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Pipeline with RNNs and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_DOCUMENT_LENGTH = 5000\n",
    "EMBEDDING_SIZE = 100\n",
    "n_words = 0\n",
    "MAX_LABEL = 3\n",
    "WORDS_FEATURE = 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_classification(logits, y, mode):\n",
    "    \n",
    "    predicted = tf.argmax(logits, 1)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions={\n",
    "                'class': predicted,\n",
    "                'prob': tf.nn.softmax(logits)\n",
    "            })\n",
    "    \n",
    "    objective = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        # no need to tune learning rate with Adam optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "        trainScore = optimizer.minimize(objective, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=objective, train_op=trainScore)\n",
    "    \n",
    "    evaluated = {'accuracy': tf.metrics.accuracy(labels=y, predictions=predicted)}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=objective, eval_metric_ops=evaluated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(features, labels, mode):\n",
    "    \n",
    "    word_vectors = tf.contrib.layers.embed_sequence(\n",
    "        features[WORDS_FEATURE], vocab_size=n_words, embed_dim=EMBEDDING_SIZE)\n",
    "    word_list = tf.unstack(word_vectors, axis=1)\n",
    "    \n",
    "    cell = tf.nn.rnn_cell.GRUCell(EMBEDDING_SIZE)\n",
    "    \n",
    "    _, encoding = tf.nn.static_rnn(cell, word_list, dtype=tf.float32)\n",
    "    \n",
    "    logits = tf.layers.dense(encoding, MAX_LABEL, activation=None)\n",
    "    \n",
    "    return softmax_classification(logits=logits, y=labels, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-fffca9111aff>:4: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    }
   ],
   "source": [
    "global n_words\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "trainTransform = processor.fit_transform(trainSet.text)\n",
    "testTransform = processor.fit_transform(testSet.text)\n",
    "trainTransform = np.array(list(trainTransform))\n",
    "testTransform = np.array(list(testTransform))\n",
    "\n",
    "n_words = len(processor.vocabulary_)\n",
    "num_steps = 100 # number of optimization steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainLabels = np.array(trainSet.toxicity)\n",
    "testLabels = np.array(testSet.toxicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn = tf.estimator.Estimator(model_fn=RNN)\n",
    "trainFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={WORDS_FEATURE: trainTransform},\n",
    "    y=trainLabels,\n",
    "    batch_size=len(trainTransform),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "rnn.train(input_fn=trainFunc, steps=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={WORDS_FEATURE: testTransform}, y=testLabels, num_epochs=1, shuffle=False)\n",
    "pred = rnn.predict(input_fn=testFunc)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred['text'] = list(testSet.text)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = np.array(pred['class'])\n",
    "print(classification_report_imbalanced(predicted, testSet.toxicity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(rnn, 'pipeline_RNN.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
