{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel, ParamGridBuilder\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import * \n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SQLContext, SparkSession, Row\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyod.models.loci import LOCI\n",
    "import pyflux as pf\n",
    "from google.cloud import bigquery\n",
    "from kafka import KafkaConsumer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @RihannaHasAids: aight game over. dykes had...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dude said ice jj fish created player on 2k ret...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not in the business of submitting to no bitch ...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When did it become cool to ne stupid? This tea...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peace fags, just remember I'm best Lux support...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  RT @RihannaHasAids: aight game over. dykes had...     42\n",
       "1  Dude said ice jj fish created player on 2k ret...     70\n",
       "2  not in the business of submitting to no bitch ...     83\n",
       "3  When did it become cool to ne stupid? This tea...     53\n",
       "4  Peace fags, just remember I'm best Lux support...     78"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('toxic-data/tweets.csv', encoding='latin-1')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-13 11:31:30</td>\n",
       "      <td>RT @RihannaHasAids: aight game over. dykes had...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-13 12:31:30</td>\n",
       "      <td>Dude said ice jj fish created player on 2k ret...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-13 13:31:30</td>\n",
       "      <td>not in the business of submitting to no bitch ...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-13 14:31:30</td>\n",
       "      <td>When did it become cool to ne stupid? This tea...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-13 15:31:30</td>\n",
       "      <td>Peace fags, just remember I'm best Lux support...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp                                               text  \\\n",
       "0 2018-04-13 11:31:30  RT @RihannaHasAids: aight game over. dykes had...   \n",
       "1 2018-04-13 12:31:30  Dude said ice jj fish created player on 2k ret...   \n",
       "2 2018-04-13 13:31:30  not in the business of submitting to no bitch ...   \n",
       "3 2018-04-13 14:31:30  When did it become cool to ne stupid? This tea...   \n",
       "4 2018-04-13 15:31:30  Peace fags, just remember I'm best Lux support...   \n",
       "\n",
       "   label  \n",
       "0     42  \n",
       "1     70  \n",
       "2     83  \n",
       "3     53  \n",
       "4     78  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['timestamp'] = \"2018-04-13 10:31:30\"\n",
    "tweets.timestamp = pd.to_datetime(tweets.timestamp)\n",
    "offsets = [pd.DateOffset(hours=i) for i in range(1, tweets.shape[0])]\n",
    "for i in range(len(offsets)):\n",
    "    tweets.loc[i,'timestamp'] += offsets[i]\n",
    "tweets = tweets.set_index(\"timestamp\").reset_index()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets.iloc[0:250,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.to_csv(\"toxic-data/tweets-timestamped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Service Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('mltox').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = \"spark-gradientboosting-toxic-tagger-cv\"\n",
    "FORECAST_WINDOW_PCT = 0.25\n",
    "FORECAST_MCMC_SIMULATIONS = 10000 # tunable\n",
    "STREAMED_FILENAME = \"toxic-data/tweets-timestamped.csv\"\n",
    "BQ_DATASET_NAME = \"MLTOX\"\n",
    "BQ_TIME_SERIES_TABLE = \"TIME_SERIES\"\n",
    "BQ_FORECAST_TABLE = \"FORECAST\"\n",
    "###  KAFKA parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanText(column):\n",
    "    return F.trim(F.lower(F.regexp_replace(column, '([^\\s\\w_]|_)+', ''))).alias('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spark Streaming component is the Kafka consumer\n",
    "# streams messages from Kafka into a spark dataframe or alternatively a .csv\n",
    "def consumeKafka():\n",
    "    pass\n",
    "\n",
    "def writeToBigQuery(df, dataset_id, table_id):\n",
    "    client = bigquery.Client()\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table = client.get_table(table_ref) # API request\n",
    "    rowsToInsert = list(df.itertuples(index=False, name=None))\n",
    "    client.insert_rows(table, rowsToInsert) # API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tagAnomalies(df):\n",
    "    values = df.prediction.values.reshape(-1,1)\n",
    "    anomalyDetector = LOCI()\n",
    "    anomalyDetector.fit(values)\n",
    "    anomalyLabels = np.asarray(anomalyDetector.labels_)\n",
    "    df['isAnomaly'] = anomalyLabels\n",
    "    return df\n",
    "\n",
    "def predict():\n",
    "    test = spark.read.csv(STREAMED_FILENAME, header=True, mode=\"DROPMALFORMED\")\n",
    "    test = test.select(F.col(\"timestamp\"), cleanText(F.col(\"text\")))\n",
    "    times = test.select(\"timestamp\")\n",
    "    test = test.drop(\"timestamp\")\n",
    "    toxicTagger = PipelineModel.load(MODEL_PATH)\n",
    "    predictions = toxicTagger.transform(test).select(F.col(\"prediction\"))\n",
    "    testIndex = predictions.withColumn(\"id\", F.monotonically_increasing_id())\n",
    "    timesIndex = times.withColumn(\"id\", F.monotonically_increasing_id())\n",
    "    tagged = timesIndex.join(testIndex, \"id\", \"inner\").drop(\"id\")\n",
    "    tagged = tagged.withColumn(\"datetime\", F.from_unixtime(F.unix_timestamp(\"timestamp\", \"yyyy-MM-dd HH:mm:ss\")))\n",
    "    tagged = tagged.select(F.col(\"datetime\"), F.col(\"prediction\"))\n",
    "    tagged = tagged.withColumn(\"timestamp\", F.date_trunc(\"hour\", F.col(\"datetime\").cast(\"timestamp\")))\n",
    "    tagged = tagged.select(F.col(\"timestamp\"), F.col(\"prediction\"))\n",
    "    result = tagged.groupBy(\"timestamp\").mean(\"prediction\").sort(F.col(\"timestamp\").asc())\n",
    "    result = result.na.drop(subset=[\"timestamp\", \"avg(prediction)\"])\n",
    "    result = result.toPandas()\n",
    "    result['timestamp'] = pd.to_datetime(result.timestamp)\n",
    "    result.columns = ['timestamp', 'prediction']\n",
    "    return result\n",
    "\n",
    "def forecast(df):\n",
    "\n",
    "    #def runForecastModel(df):\n",
    "        #forecaster = ToxicityForecaster(df.prediction.values)\n",
    "        #return forecaster.forecast()\n",
    "\n",
    "    #_, forecasted = runForecastModel(df)\n",
    "    #start = [df.timestamp.iloc[-1]] * FORECAST_WINDOW\n",
    "    #forecastDF = pd.DataFrame({'timestamp': start})\n",
    "    #forecastDF['timestamp'] = pd.to_datetime(forecastDF.timestamp)\n",
    "    #offsets = [pd.DateOffset(hours=i) for i in range(1, FORECAST_WINDOW)]\n",
    "    #for i in range(len(offsets)):\n",
    "        #forecastDF.loc[i,'timestamp'] += offsets[i]\n",
    "    #forecastDF['prediction'] = forecasted\n",
    "    #return forecastDF\n",
    "\n",
    "    forecast_window = int(df.shape[0] * FORECAST_WINDOW_PCT)\n",
    "    forecasted = pd.DataFrame(columns=['timestamp','prediction'])\n",
    "    model = None\n",
    "    if forecast_window > 0:\n",
    "        ts = df.set_index('timestamp')\n",
    "        model = pf.GARCH(p=1, q=1, data=ts)\n",
    "        model.fit('M-H', nsims=FORECAST_MCMC_SIMULATIONS)\n",
    "        forecasted = model.predict(forecast_window).reset_index()\n",
    "    return forecasted, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    # consumeKafka()\n",
    "    history = predict()\n",
    "    history = tagAnomalies(history)\n",
    "    forecasted, model = forecast(history)\n",
    "    print(history.head())\n",
    "    print(forecasted.head())\n",
    "    #writeToBigQuery(history, BQ_DATASET_NAME, BQ_TIME_SERIES_TABLE)\n",
    "    #writeToBigQuery(forecast, BQ_DATASET_NAME, BQ_FORECAST_TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('mltox').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = spark.read.csv(STREAMED_FILENAME, header=True, mode=\"DROPMALFORMED\")\n",
    "test = test.select(F.col(\"timestamp\"), cleanText(F.col(\"text\")))\n",
    "times = test.select(\"timestamp\")\n",
    "test = test.drop(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toxicTagger = PipelineModel.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        prediction|\n",
      "+------------------+\n",
      "|50.062105637329594|\n",
      "| 50.71760941386791|\n",
      "| 53.27285813640033|\n",
      "|50.062105637329594|\n",
      "|50.062105637329594|\n",
      "|50.062105637329594|\n",
      "| 51.07780263384459|\n",
      "|50.062105637329594|\n",
      "| 53.09267422891177|\n",
      "|50.062105637329594|\n",
      "|50.062105637329594|\n",
      "|50.062105637329594|\n",
      "| 50.04597062758577|\n",
      "|  53.6237102795118|\n",
      "|50.062105637329594|\n",
      "|50.062105637329594|\n",
      "|50.062105637329594|\n",
      "| 59.75237995683988|\n",
      "|50.062105637329594|\n",
      "|53.478748590885175|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = toxicTagger.transform(test).select(F.col(\"prediction\"))\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testIndex = predictions.withColumn(\"id\", F.monotonically_increasing_id())\n",
    "timesIndex = times.withColumn(\"id\", F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|          timestamp|        prediction|\n",
      "+-------------------+------------------+\n",
      "|2018-04-13 11:31:30|50.062105637329594|\n",
      "|2018-04-13 12:31:30| 50.71760941386791|\n",
      "|2018-04-13 13:31:30| 53.27285813640033|\n",
      "|2018-04-13 14:31:30|50.062105637329594|\n",
      "|2018-04-13 15:31:30|50.062105637329594|\n",
      "|2018-04-13 16:31:30|50.062105637329594|\n",
      "|2018-04-13 17:31:30| 51.07780263384459|\n",
      "|2018-04-13 18:31:30|50.062105637329594|\n",
      "|2018-04-13 19:31:30| 53.09267422891177|\n",
      "|2018-04-13 21:31:30|50.062105637329594|\n",
      "|2018-04-13 22:31:30|50.062105637329594|\n",
      "|2018-04-13 23:31:30|50.062105637329594|\n",
      "|2018-04-14 00:31:30| 50.04597062758577|\n",
      "|2018-04-14 01:31:30|  53.6237102795118|\n",
      "|2018-04-14 02:31:30|50.062105637329594|\n",
      "|2018-04-14 03:31:30|50.062105637329594|\n",
      "|2018-04-14 04:31:30|50.062105637329594|\n",
      "|2018-04-14 05:31:30| 59.75237995683988|\n",
      "|2018-04-14 06:31:30|50.062105637329594|\n",
      "|2018-04-14 07:31:30|53.478748590885175|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagged = timesIndex.join(testIndex, \"id\", \"inner\").drop(\"id\")\n",
    "tagged.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|           datetime|        prediction|\n",
      "+-------------------+------------------+\n",
      "|2018-04-13 11:31:30|50.062105637329594|\n",
      "|2018-04-13 12:31:30| 50.71760941386791|\n",
      "|2018-04-13 13:31:30| 53.27285813640033|\n",
      "|2018-04-13 14:31:30|50.062105637329594|\n",
      "|2018-04-13 15:31:30|50.062105637329594|\n",
      "|2018-04-13 16:31:30|50.062105637329594|\n",
      "|2018-04-13 17:31:30| 51.07780263384459|\n",
      "|2018-04-13 18:31:30|50.062105637329594|\n",
      "|2018-04-13 19:31:30| 53.09267422891177|\n",
      "|2018-04-13 21:31:30|50.062105637329594|\n",
      "|2018-04-13 22:31:30|50.062105637329594|\n",
      "|2018-04-13 23:31:30|50.062105637329594|\n",
      "|2018-04-14 00:31:30| 50.04597062758577|\n",
      "|2018-04-14 01:31:30|  53.6237102795118|\n",
      "|2018-04-14 02:31:30|50.062105637329594|\n",
      "|2018-04-14 03:31:30|50.062105637329594|\n",
      "|2018-04-14 04:31:30|50.062105637329594|\n",
      "|2018-04-14 05:31:30| 59.75237995683988|\n",
      "|2018-04-14 06:31:30|50.062105637329594|\n",
      "|2018-04-14 07:31:30|53.478748590885175|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagged = tagged.withColumn(\"datetime\", F.from_unixtime(F.unix_timestamp(\"timestamp\", \"yyyy-MM-dd HH:mm:ss\")))\n",
    "tagged = tagged.select(F.col(\"datetime\"), F.col(\"prediction\"))\n",
    "tagged.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|          timestamp|        prediction|\n",
      "+-------------------+------------------+\n",
      "|2018-04-13 11:00:00|50.062105637329594|\n",
      "|2018-04-13 12:00:00| 50.71760941386791|\n",
      "|2018-04-13 13:00:00| 53.27285813640033|\n",
      "|2018-04-13 14:00:00|50.062105637329594|\n",
      "|2018-04-13 15:00:00|50.062105637329594|\n",
      "|2018-04-13 16:00:00|50.062105637329594|\n",
      "|2018-04-13 17:00:00| 51.07780263384459|\n",
      "|2018-04-13 18:00:00|50.062105637329594|\n",
      "|2018-04-13 19:00:00| 53.09267422891177|\n",
      "|2018-04-13 21:00:00|50.062105637329594|\n",
      "|2018-04-13 22:00:00|50.062105637329594|\n",
      "|2018-04-13 23:00:00|50.062105637329594|\n",
      "|2018-04-14 00:00:00| 50.04597062758577|\n",
      "|2018-04-14 01:00:00|  53.6237102795118|\n",
      "|2018-04-14 02:00:00|50.062105637329594|\n",
      "|2018-04-14 03:00:00|50.062105637329594|\n",
      "|2018-04-14 04:00:00|50.062105637329594|\n",
      "|2018-04-14 05:00:00| 59.75237995683988|\n",
      "|2018-04-14 06:00:00|50.062105637329594|\n",
      "|2018-04-14 07:00:00|53.478748590885175|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagged = tagged.withColumn(\"timestamp\", F.date_trunc(\"hour\", F.col(\"datetime\").cast(\"timestamp\")))\n",
    "tagged = tagged.select(F.col(\"timestamp\"), F.col(\"prediction\"))\n",
    "tagged.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|          timestamp|   avg(prediction)|\n",
      "+-------------------+------------------+\n",
      "|2018-04-13 11:00:00|50.062105637329594|\n",
      "|2018-04-13 12:00:00| 50.71760941386791|\n",
      "|2018-04-13 13:00:00| 53.27285813640033|\n",
      "|2018-04-13 14:00:00|50.062105637329594|\n",
      "|2018-04-13 15:00:00|50.062105637329594|\n",
      "|2018-04-13 16:00:00|50.062105637329594|\n",
      "|2018-04-13 17:00:00| 51.07780263384459|\n",
      "|2018-04-13 18:00:00|50.062105637329594|\n",
      "|2018-04-13 19:00:00| 53.09267422891177|\n",
      "|2018-04-13 21:00:00|50.062105637329594|\n",
      "|2018-04-13 22:00:00|50.062105637329594|\n",
      "|2018-04-13 23:00:00|50.062105637329594|\n",
      "|2018-04-14 00:00:00| 50.04597062758577|\n",
      "|2018-04-14 01:00:00|  53.6237102795118|\n",
      "|2018-04-14 02:00:00|50.062105637329594|\n",
      "|2018-04-14 03:00:00|50.062105637329594|\n",
      "|2018-04-14 04:00:00|50.062105637329594|\n",
      "|2018-04-14 05:00:00| 59.75237995683988|\n",
      "|2018-04-14 06:00:00|50.062105637329594|\n",
      "|2018-04-14 07:00:00|53.478748590885175|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = tagged.groupBy(\"timestamp\").mean(\"prediction\").sort(F.col(\"timestamp\").asc())\n",
    "result = result.na.drop(subset=[\"timestamp\", \"avg(prediction)\"])\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|          timestamp|   avg(prediction)|\n",
      "+-------------------+------------------+\n",
      "|2018-04-13 11:00:00|50.062105637329594|\n",
      "|2018-04-13 12:00:00| 50.71760941386791|\n",
      "|2018-04-13 13:00:00| 53.27285813640033|\n",
      "|2018-04-13 14:00:00|50.062105637329594|\n",
      "|2018-04-13 15:00:00|50.062105637329594|\n",
      "|2018-04-13 16:00:00|50.062105637329594|\n",
      "|2018-04-13 17:00:00| 51.07780263384459|\n",
      "|2018-04-13 18:00:00|50.062105637329594|\n",
      "|2018-04-13 19:00:00| 53.09267422891177|\n",
      "|2018-04-13 21:00:00|50.062105637329594|\n",
      "|2018-04-13 22:00:00|50.062105637329594|\n",
      "|2018-04-13 23:00:00|50.062105637329594|\n",
      "|2018-04-14 00:00:00| 50.04597062758577|\n",
      "|2018-04-14 01:00:00|  53.6237102795118|\n",
      "|2018-04-14 02:00:00|50.062105637329594|\n",
      "|2018-04-14 03:00:00|50.062105637329594|\n",
      "|2018-04-14 04:00:00|50.062105637329594|\n",
      "|2018-04-14 05:00:00| 59.75237995683988|\n",
      "|2018-04-14 06:00:00|50.062105637329594|\n",
      "|2018-04-14 07:00:00|53.478748590885175|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = tagged.groupBy(F.col(\"timestamp\")).agg(F.mean(F.col(\"prediction\"))).sort(F.col(\"timestamp\").asc())\n",
    "result = result.na.drop(subset=[\"timestamp\", \"avg(prediction)\"])\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-13 11:00:00</td>\n",
       "      <td>50.062106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-13 12:00:00</td>\n",
       "      <td>50.717609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-13 13:00:00</td>\n",
       "      <td>53.272858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-13 14:00:00</td>\n",
       "      <td>50.062106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-13 15:00:00</td>\n",
       "      <td>50.062106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  prediction\n",
       "0 2018-04-13 11:00:00   50.062106\n",
       "1 2018-04-13 12:00:00   50.717609\n",
       "2 2018-04-13 13:00:00   53.272858\n",
       "3 2018-04-13 14:00:00   50.062106\n",
       "4 2018-04-13 15:00:00   50.062106"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.toPandas()\n",
    "result['timestamp'] = pd.to_datetime(result.timestamp)\n",
    "result.columns = ['timestamp', 'prediction']\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prediction</th>\n",
       "      <th>isAnomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-13 11:00:00</td>\n",
       "      <td>50.062106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-13 12:00:00</td>\n",
       "      <td>50.717609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-13 13:00:00</td>\n",
       "      <td>53.272858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-13 14:00:00</td>\n",
       "      <td>50.062106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-13 15:00:00</td>\n",
       "      <td>50.062106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  prediction  isAnomaly\n",
       "0 2018-04-13 11:00:00   50.062106          0\n",
       "1 2018-04-13 12:00:00   50.717609          0\n",
       "2 2018-04-13 13:00:00   53.272858          1\n",
       "3 2018-04-13 14:00:00   50.062106          0\n",
       "4 2018-04-13 15:00:00   50.062106          0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tagAnomalies(result)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prediction</th>\n",
       "      <th>isAnomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-13 11:00:00</td>\n",
       "      <td>50.062106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-13 12:00:00</td>\n",
       "      <td>50.717609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-13 13:00:00</td>\n",
       "      <td>53.272858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-13 14:00:00</td>\n",
       "      <td>50.062106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-13 15:00:00</td>\n",
       "      <td>50.062106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  prediction  isAnomaly\n",
       "0 2018-04-13 11:00:00   50.062106          0\n",
       "1 2018-04-13 12:00:00   50.717609          0\n",
       "2 2018-04-13 13:00:00   53.272858          1\n",
       "3 2018-04-13 14:00:00   50.062106          0\n",
       "4 2018-04-13 15:00:00   50.062106          0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = tagAnomalies(predict())\n",
    "history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate of Metropolis-Hastings is 0.001\n",
      "Acceptance rate of Metropolis-Hastings is 0.1485\n",
      "Acceptance rate of Metropolis-Hastings is 0.215\n",
      "Acceptance rate of Metropolis-Hastings is 0.281\n",
      "\n",
      "Tuning complete! Now sampling.\n",
      "Acceptance rate of Metropolis-Hastings is 0.273\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-21 07:00:00</td>\n",
       "      <td>4.813088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-21 08:00:00</td>\n",
       "      <td>4.813088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-21 09:00:00</td>\n",
       "      <td>4.813088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-21 10:00:00</td>\n",
       "      <td>4.813088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-21 11:00:00</td>\n",
       "      <td>4.813088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  prediction\n",
       "0 2018-04-21 07:00:00    4.813088\n",
       "1 2018-04-21 08:00:00    4.813088\n",
       "2 2018-04-21 09:00:00    4.813088\n",
       "3 2018-04-21 10:00:00    4.813088\n",
       "4 2018-04-21 11:00:00    4.813088"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast, model = forecast(history)\n",
    "forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate of Metropolis-Hastings is 0.00205\n",
      "Acceptance rate of Metropolis-Hastings is 0.15125\n",
      "Acceptance rate of Metropolis-Hastings is 0.21225\n",
      "Acceptance rate of Metropolis-Hastings is 0.28525\n",
      "\n",
      "Tuning complete! Now sampling.\n",
      "Acceptance rate of Metropolis-Hastings is 0.278575\n",
      "            timestamp  prediction  isAnomaly\n",
      "0 2018-04-13 11:00:00   50.062106          0\n",
      "1 2018-04-13 12:00:00   50.717609          0\n",
      "2 2018-04-13 13:00:00   53.272858          1\n",
      "3 2018-04-13 14:00:00   50.062106          0\n",
      "4 2018-04-13 15:00:00   50.062106          0\n",
      "            timestamp  prediction\n",
      "0 2018-04-21 07:00:00    4.947318\n",
      "1 2018-04-21 08:00:00    4.947318\n",
      "2 2018-04-21 09:00:00    4.947318\n",
      "3 2018-04-21 10:00:00    4.947318\n",
      "4 2018-04-21 11:00:00    4.947318\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
